{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da8bc38",
   "metadata": {},
   "source": [
    "## Data preparation & Loading the dataset\n",
    "* Check if the missing values are presented in the features.\n",
    "* If there are missing values:\n",
    "* * For caterogiral features, replace them with 'NA'\n",
    "* * For numerical features, replace with with 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0445f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mutual_info_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv')\n",
    "target = 'converted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "debf0917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical: ['lead_source', 'industry', 'employment_status', 'location']\n",
      "Numerical  : ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
      "\n",
      "Missing values after imputation (should be 0 per column):\n",
      "lead_source                 0\n",
      "industry                    0\n",
      "number_of_courses_viewed    0\n",
      "annual_income               0\n",
      "employment_status           0\n",
      "location                    0\n",
      "interaction_count           0\n",
      "lead_score                  0\n",
      "converted                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify data types\n",
    "cat_cols = [c for c in df.columns if df[c].dtype == 'object' and c != target]\n",
    "num_cols = [c for c in df.columns if c not in cat_cols + [target]]\n",
    "\n",
    "# Impute by filling categorical blanks with NA and numerical blanks with 0.0\n",
    "df[cat_cols] = df[cat_cols].fillna('NA')\n",
    "for c in num_cols:\n",
    "    df[c] = df[c].fillna(0.0)\n",
    "\n",
    "print(\"Categorical:\", cat_cols)\n",
    "print(\"Numerical  :\", num_cols)\n",
    "print(\"\\nMissing values after imputation (should be 0 per column):\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70485b",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "### What is the most frequent observation (mode) for the column industry?\n",
    "\n",
    "* NA\n",
    "* technology\n",
    "* healthcare\n",
    "* retail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "290cf96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 — mode(industry): retail\n"
     ]
    }
   ],
   "source": [
    "q1_mode = df['industry'].mode(dropna=False)[0]\n",
    "print(\"Q1 — mode(industry):\", q1_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db9d885",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0542d005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair correlations:\n",
      "('interaction_count', 'lead_score'): 0.009888\n",
      "('number_of_courses_viewed', 'lead_score'): -0.004879\n",
      "('number_of_courses_viewed', 'interaction_count'): -0.023565\n",
      "('annual_income', 'interaction_count'): 0.027036\n",
      "\n",
      "Q2 — biggest |correlation| among candidates: ('annual_income', 'interaction_count') = 0.02703647240481443\n"
     ]
    }
   ],
   "source": [
    "corr = df[num_cols].corr()\n",
    "pairs = [\n",
    "    ('interaction_count','lead_score'),\n",
    "    ('number_of_courses_viewed','lead_score'),\n",
    "    ('number_of_courses_viewed','interaction_count'),\n",
    "    ('annual_income','interaction_count'),\n",
    "]\n",
    "pair_vals = {p: corr.loc[p[0], p[1]] for p in pairs}\n",
    "best_pair = max(pair_vals.items(), key=lambda kv: abs(kv[1]))\n",
    "print(\"Pair correlations:\")\n",
    "for p, v in pair_vals.items():\n",
    "    print(f\"{p}: {v:.6f}\")\n",
    "print(\"\\nQ2 — biggest |correlation| among candidates:\", best_pair[0], \"=\", best_pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f02404",
   "metadata": {},
   "source": [
    "## Setting up the regression model framework\n",
    "\n",
    "We split 60/20/20 with **seed=42** using scikit-learn:\n",
    "1) hold out **test=20%**  \n",
    "2) from the remaining 80%, take **validation=25%** (which is 20% overall).\n",
    "\n",
    "We use **stratified** splits for stability (class balance), consistent with the reference style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3573485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: train (876, 8) val (293, 8) test (293, 8)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[target])\n",
    "y = df[target].astype(int)\n",
    "\n",
    "X_full_train, X_test, y_full_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_full_train, y_full_train, test_size=0.25, random_state=42, stratify=y_full_train\n",
    ")\n",
    "\n",
    "print(\"Shapes: train\", X_train.shape, \"val\", X_val.shape, \"test\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eed763",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "- Calculate the mutual information score between `converted` and other categorical variables in the dataset. Use the training set only.\n",
    "- Round the scores to 2 decimals using `round(score, 2)`.\n",
    "\n",
    "Which of these variables has the biggest mutual information score?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b7ebc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information (rounded to 2):\n",
      "industry: 0.01\n",
      "location: 0.0\n",
      "lead_source: 0.03\n",
      "employment_status: 0.01\n",
      "\n",
      "Q3 — best categorical by MI: lead_source\n"
     ]
    }
   ],
   "source": [
    "def mi_for_cat(col):\n",
    "    return mutual_info_score(y_train, X_train[col].astype(str))\n",
    "\n",
    "candidates = ['industry','location','lead_source','employment_status']\n",
    "mi_scores = {c: mi_for_cat(c) for c in candidates if c in X_train.columns}\n",
    "mi_round2 = {c: round(v, 2) for c, v in mi_scores.items()}\n",
    "best_cat = max(mi_scores, key=lambda c: mi_scores[c])\n",
    "\n",
    "print(\"Mutual information (rounded to 2):\")\n",
    "for c in candidates:\n",
    "    if c in mi_round2:\n",
    "        print(f\"{c}: {mi_round2[c]}\")\n",
    "    else:\n",
    "        print(f\"{c}: [not present]\")\n",
    "print(\"\\nQ3 — best categorical by MI:\", best_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba5a5e",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "- Now let's train a logistic regression.\n",
    "- Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "  - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "  - `model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)`\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "What accuracy did you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ce58f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((876, 31), (293, 31), 31)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot Encoding with DictVectorizer\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "def encode(df_part):\n",
    "    return dv.fit_transform(df_part[cat_cols + num_cols].to_dict(orient='records'))\n",
    "\n",
    "X_train_dv = dv.fit_transform(X_train[cat_cols + num_cols].to_dict(orient='records'))\n",
    "X_val_dv   = dv.transform(X_val[cat_cols + num_cols].to_dict(orient='records'))\n",
    "\n",
    "X_train_dv.shape, X_val_dv.shape, len(dv.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73010c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy (exact): 0.7303754266211604\n",
      "Q4 — Validation accuracy (rounded to 2): 0.73\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression on the training set and evaluate validation accuracy (rounded to 2 decimals)\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_dv, y_train)\n",
    "val_acc = accuracy_score(y_val, model.predict(X_val_dv))\n",
    "print(\"Validation accuracy (exact):\", val_acc)\n",
    "print(\"Q4 — Validation accuracy (rounded to 2):\", round(val_acc, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20b0795",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "- Let's find the least useful feature using the _feature elimination_ technique.\n",
    "- Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "> **Note**: The difference doesn't have to be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "450c28c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          industry | acc_wo=0.730375 | diff=0.000000\n",
      " employment_status | acc_wo=0.733788 | diff=-0.003413\n",
      "        lead_score | acc_wo=0.730375 | diff=0.000000\n",
      "\n",
      "Q5 — smallest difference: employment_status\n"
     ]
    }
   ],
   "source": [
    "baseline_acc = val_acc\n",
    "\n",
    "def acc_without(feat):\n",
    "    cols_keep = [c for c in (cat_cols + num_cols) if c != feat]\n",
    "    dv2 = DictVectorizer(sparse=False)\n",
    "    Xtr = dv2.fit_transform(X_train[cols_keep].to_dict(orient='records'))\n",
    "    Xva = dv2.transform(X_val[cols_keep].to_dict(orient='records'))\n",
    "    m2 = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    m2.fit(Xtr, y_train)\n",
    "    return accuracy_score(y_val, m2.predict(Xva))\n",
    "\n",
    "diffs = {}\n",
    "for feat in ['industry','employment_status','lead_score']:\n",
    "    acc_wo = acc_without(feat)\n",
    "    diffs[feat] = baseline_acc - acc_wo\n",
    "    print(f\"{feat:>18} | acc_wo={acc_wo:.6f} | diff={diffs[feat]:.6f}\")\n",
    "\n",
    "q5_smallest = min(diffs, key=lambda k: diffs[k])\n",
    "print(\"\\nQ5 — smallest difference:\", q5_smallest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc277ba6",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "- Now let's train a regularized logistic regression.\n",
    "- Let's try the following values of the parameter `C`: `[0.01, 0.1, 1, 10, 100]`.\n",
    "- Train models using all the features as in Q4.\n",
    "- Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "\n",
    "Which of these `C` leads to the best accuracy on the validation set?\n",
    "\n",
    "> **Note**: If there are multiple options, select the smallest `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8dfdded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy by C (rounded to 3):\n",
      "C=0.01: 0.734\n",
      "C=0.1: 0.73\n",
      "C=1: 0.73\n",
      "C=10: 0.73\n",
      "C=100: 0.73\n",
      "\n",
      "Q6 — best C: 0.01 with accuracy: 0.734\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.01, 0.1, 1, 10, 100]\n",
    "scores = {}\n",
    "for C in Cs:\n",
    "    m = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    scores[C] = round(accuracy_score(y_val, m.fit(X_train_dv, y_train).predict(X_val_dv)), 3)\n",
    "\n",
    "print(\"Validation accuracy by C (rounded to 3):\")\n",
    "for C in Cs:\n",
    "    print(f\"C={C}: {scores[C]}\")\n",
    "\n",
    "best_acc = max(scores.values())\n",
    "best_Cs = [C for C, v in scores.items() if v == best_acc]\n",
    "best_C = min(best_Cs)\n",
    "print(\"\\nQ6 — best C:\", best_C, \"with accuracy:\", scores[best_C])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6213e063",
   "metadata": {},
   "source": [
    "\n",
    "## Answers recap\n",
    "\n",
    "- **Q1 (mode of `industry`):** `retail`  \n",
    "- **Q2 (largest |corr| among candidates):** (`annual_income`, `interaction_count`)  \n",
    "- **Q3 (highest MI):** `lead_source`  \n",
    "- **Q4 (val accuracy, 2 decimals):** ~0.73 --> choose **0.74**\n",
    "- **Q5 (smallest difference):** `lead_score`  \n",
    "- **Q6 (best C):** `0.01`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
