{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddcff871",
   "metadata": {},
   "source": [
    "\n",
    "## 0. Setup\n",
    "\n",
    "Minimal stack: `pandas`/`numpy` for data, `scikit-learn` for splitting, preprocessing, modeling, and metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a616de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mutual_info_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e9e474",
   "metadata": {},
   "source": [
    "## 1. Load data and identify schema\n",
    "\n",
    "**Target:** `converted` (has the client signed up).  \n",
    "**Features:** We'll programmatically identify categorical (object dtype) vs numerical and then confirm the specific columns used later in the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0229f300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull in the data and preview it's contents\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ec70db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['lead_source', 'industry', 'employment_status', 'location']\n",
      "Numeric columns: ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
      "\n",
      "Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "target_col = 'converted'\n",
    "assert target_col in df.columns, \"Expected 'converted' in dataset\"\n",
    "\n",
    "# Identify by dtype\n",
    "categorical_cols = [c for c in df.columns if df[c].dtype == 'object' and c != target_col]\n",
    "numeric_cols = [c for c in df.columns if c not in categorical_cols + [target_col]]\n",
    "\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"\\nPreview:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527eb8c",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Data preparation (as required)\n",
    "\n",
    "**Missing values policy (from the prompt):**\n",
    "- For **categorical** features: replace missing with `'NA'`\n",
    "- For **numerical** features: replace missing with `0.0`\n",
    "\n",
    "We apply this **directly to the raw DataFrame** so all downstream steps use the imputed values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e3266a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing values per column:\n",
      "lead_source                 0\n",
      "industry                    0\n",
      "number_of_courses_viewed    0\n",
      "annual_income               0\n",
      "employment_status           0\n",
      "location                    0\n",
      "interaction_count           0\n",
      "lead_score                  0\n",
      "converted                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Impute per the instructions\n",
    "df[categorical_cols] = df[categorical_cols].fillna('NA')\n",
    "for c in numeric_cols:\n",
    "    df[c] = df[c].fillna(0.0)\n",
    "\n",
    "# Quick check after imputation\n",
    "print(\"Remaining missing values per column:\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf7887",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Q1 — Most frequent observation (mode) for `industry`\n",
    "\n",
    "Compute the mode after imputation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "928a1e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode for 'industry': retail\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mode_industry = df['industry'].mode(dropna=False)[0]\n",
    "print(\"Mode for 'industry':\", mode_industry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfaee69",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Q2 — Correlation matrix among numeric features\n",
    "\n",
    "We compute the Pearson correlation on the **numerical** features and then compare only the candidate pairs listed in the question:\n",
    "\n",
    "- (`interaction_count`, `lead_score`)\n",
    "- (`number_of_courses_viewed`, `lead_score`)\n",
    "- (`number_of_courses_viewed`, `interaction_count`)\n",
    "- (`annual_income`, `interaction_count`)\n",
    "\n",
    "We choose the pair with the **largest absolute** correlation among these candidates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15f7b168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair correlations:\n",
      "('interaction_count', 'lead_score'): 0.009888\n",
      "('number_of_courses_viewed', 'lead_score'): -0.004879\n",
      "('number_of_courses_viewed', 'interaction_count'): -0.023565\n",
      "('annual_income', 'interaction_count'): 0.027036\n",
      "\n",
      "Best pair by absolute correlation: ('annual_income', 'interaction_count') with 0.02703647240481443\n"
     ]
    }
   ],
   "source": [
    "\n",
    "corr = df[numeric_cols].corr(method='pearson')\n",
    "pairs = [\n",
    "    ('interaction_count','lead_score'),\n",
    "    ('number_of_courses_viewed','lead_score'),\n",
    "    ('number_of_courses_viewed','interaction_count'),\n",
    "    ('annual_income','interaction_count'),\n",
    "]\n",
    "\n",
    "def pair_corr(a,b):\n",
    "    return corr.loc[a,b] if (a in corr.index and b in corr.columns) else np.nan\n",
    "\n",
    "pair_corrs = {p: pair_corr(*p) for p in pairs}\n",
    "pair_corrs_abs = {p: abs(v) if not np.isnan(v) else np.nan for p,v in pair_corrs.items()}\n",
    "best_pair = max(pair_corrs_abs, key=lambda p: pair_corrs_abs[p])\n",
    "\n",
    "print(\"Pair correlations:\")\n",
    "for p, v in pair_corrs.items():\n",
    "    print(f\"{p}: {v:.6f}\")\n",
    "print(\"\\nBest pair by absolute correlation:\", best_pair, \"with\", pair_corrs[best_pair])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a10de3",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Split data (train/val/test = 60/20/20) using scikit-learn\n",
    "\n",
    "The problem statement specifies **`train_test_split` with seed=42**.  \n",
    "To get 60/20/20, we do a **two-step split**:\n",
    "1. Split off test=20%\n",
    "2. Split the remaining 80% into train/val with val=25% (i.e., 20% of original).\n",
    "\n",
    "We also perform a **stratified** split (on the target) to maintain class balance; this can affect accuracy slightly but is common practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4bc191f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> train: (876, 8) val: (293, 8) test: (293, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].astype(int)\n",
    "\n",
    "# 20% test\n",
    "X_full_train, X_test, y_full_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "# 25% of remaining 80% -> 20% overall for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_full_train, y_full_train, test_size=0.25, random_state=42, stratify=y_full_train\n",
    ")\n",
    "\n",
    "assert target_col not in X_train.columns\n",
    "print(\"Shapes -> train:\", X_train.shape, \"val:\", X_val.shape, \"test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e40239",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Q3 — Mutual information (training set only) for categorical variables\n",
    "\n",
    "We compute **mutual information** between `y_train` and each categorical feature in the **training** set.  \n",
    "We report the values **rounded to 2 decimals** and identify the largest among the options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ed4d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information (rounded to 2):\n",
      "industry: 0.01\n",
      "location: 0.0\n",
      "lead_source: 0.03\n",
      "employment_status: 0.01\n",
      "\n",
      "Best among candidates: lead_source\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def categorical_mutual_info(series, yvec):\n",
    "    return mutual_info_score(yvec, series.astype(str))\n",
    "\n",
    "categorical_cols_present = [c for c in X_train.columns if X_train[c].dtype == 'object']\n",
    "mi_scores = {c: categorical_mutual_info(X_train[c], y_train) for c in categorical_cols_present}\n",
    "mi_scores_round2 = {c: round(v, 2) for c, v in mi_scores.items()}\n",
    "\n",
    "candidates = ['industry','location','lead_source','employment_status']\n",
    "present_candidates = [c for c in candidates if c in mi_scores]\n",
    "best_cat = max(present_candidates, key=lambda c: mi_scores[c])\n",
    "\n",
    "print(\"Mutual information (rounded to 2):\")\n",
    "for c in candidates:\n",
    "    if c in mi_scores_round2:\n",
    "        print(f\"{c}: {mi_scores_round2[c]}\")\n",
    "    else:\n",
    "        print(f\"{c}: [not present]\")\n",
    "\n",
    "print(\"\\nBest among candidates:\", best_cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b63c9e3",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Q4 — Logistic Regression (one-hot for categoricals)\n",
    "\n",
    "We build a **pipeline** with:\n",
    "- `OneHotEncoder(handle_unknown='ignore')` for categorical features\n",
    "- pass-through for numeric features\n",
    "- `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)`\n",
    "\n",
    "Then we compute **validation accuracy** and round to **2 decimals**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b6fe9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy (exact): 0.7303754266211604\n",
      "Validation accuracy (rounded to 2): 0.73\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categoricals = [c for c in X_train.columns if X_train[c].dtype == 'object']\n",
    "numerics = [c for c in X_train.columns if c not in categoricals]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categoricals),\n",
    "        ('num', 'passthrough', numerics)\n",
    "    ]\n",
    ")\n",
    "\n",
    "log_reg = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "pipe = Pipeline(steps=[('prep', preprocess), ('clf', log_reg)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "val_preds = pipe.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "print(\"Validation accuracy (exact):\", val_acc)\n",
    "print(\"Validation accuracy (rounded to 2):\", round(val_acc, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f799920a",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Q5 — Simple feature elimination (validation accuracy drop)\n",
    "\n",
    "We take the **baseline** (all features as in Q4), then drop **one feature at a time** and recompute validation accuracy.  \n",
    "We report the **difference** = baseline_accuracy − accuracy_without_feature for the features asked:\n",
    "\n",
    "- `'industry'`\n",
    "- `'employment_status'`\n",
    "- `'lead_score'`\n",
    "\n",
    "> The difference can be negative (i.e., the model does **better** without a feature).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4f4eebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          industry | acc_wo=0.730375 | diff=0.000000\n",
      " employment_status | acc_wo=0.733788 | diff=-0.003413\n",
      "        lead_score | acc_wo=0.730375 | diff=0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "baseline_acc = val_acc\n",
    "\n",
    "def val_acc_without(feature_name):\n",
    "    Xt_train = X_train.drop(columns=[feature_name], errors='ignore')\n",
    "    Xt_val   = X_val.drop(columns=[feature_name], errors='ignore')\n",
    "    cats = [c for c in Xt_train.columns if Xt_train[c].dtype == 'object']\n",
    "    nums = [c for c in Xt_train.columns if c not in cats]\n",
    "    pre = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore'), cats),\n",
    "                             ('num', 'passthrough', nums)])\n",
    "    model = Pipeline([('prep', pre),\n",
    "                      ('clf', LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42))])\n",
    "    model.fit(Xt_train, y_train)\n",
    "    return accuracy_score(y_val, model.predict(Xt_val))\n",
    "\n",
    "for feat in ['industry','employment_status','lead_score']:\n",
    "    acc_wo = val_acc_without(feat)\n",
    "    diff = baseline_acc - acc_wo\n",
    "    print(f\"{feat:>18} | acc_wo={acc_wo:.6f} | diff={diff:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ab43ec",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Q6 — Regularized Logistic Regression (C sweep)\n",
    "\n",
    "Try `C ∈ [0.01, 0.1, 1, 10, 100]` with the same features as Q4.  \n",
    "Compute validation accuracy **rounded to 3 decimals**. If there’s a tie, select the **smallest C**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c3a5c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy by C (rounded to 3):\n",
      "C=0.01: 0.734\n",
      "C=0.1: 0.73\n",
      "C=1: 0.73\n",
      "C=10: 0.73\n",
      "C=100: 0.73\n",
      "\n",
      "Best C: 0.01 with accuracy: 0.734\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Cs = [0.01, 0.1, 1, 10, 100]\n",
    "scores = {}\n",
    "for C in Cs:\n",
    "    model = Pipeline([('prep', preprocess),\n",
    "                      ('clf', LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42))])\n",
    "    model.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_val, model.predict(X_val))\n",
    "    scores[C] = round(acc, 3)\n",
    "\n",
    "print(\"Validation accuracy by C (rounded to 3):\")\n",
    "for C in Cs:\n",
    "    print(f\"C={C}: {scores[C]}\")\n",
    "\n",
    "best_acc = max(scores.values())\n",
    "best_Cs = [C for C, s in scores.items() if s == best_acc]\n",
    "best_C = min(best_Cs)\n",
    "print(\"\\nBest C:\", best_C, \"with accuracy:\", scores[best_C])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e921f6b2",
   "metadata": {},
   "source": [
    "## 10. Sanity checks (alternate split strategy)\n",
    "\n",
    "To ensure we didn’t misinterpret the splitting instruction, we also try **non-stratified** splits (still 60/20/20, seed=42) and compare the Q4 validation accuracy.  \n",
    "Small differences are expected because the class ratio can drift without stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ba50738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-stratified validation accuracy (rounded to 2): 0.7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Non-stratified version for comparison\n",
    "X_full_train_ns, X_test_ns, y_full_train_ns, y_test_ns = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=None\n",
    ")\n",
    "X_train_ns, X_val_ns, y_train_ns, y_val_ns = train_test_split(\n",
    "    X_full_train_ns, y_full_train_ns, test_size=0.25, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "cats_ns = [c for c in X_train_ns.columns if X_train_ns[c].dtype == 'object']\n",
    "nums_ns = [c for c in X_train_ns.columns if c not in cats_ns]\n",
    "\n",
    "pre_ns = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore'), cats_ns),\n",
    "                            ('num', 'passthrough', nums_ns)])\n",
    "pipe_ns = Pipeline([('prep', pre_ns),\n",
    "                    ('clf', LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42))])\n",
    "pipe_ns.fit(X_train_ns, y_train_ns)\n",
    "acc_ns = accuracy_score(y_val_ns, pipe_ns.predict(X_val_ns))\n",
    "print(\"Non-stratified validation accuracy (rounded to 2):\", round(acc_ns, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6733b3",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Final multiple-choice selections\n",
    "\n",
    "Based on the **stratified** split (preferred for stability) and exact computations above:\n",
    "\n",
    "- **Q1 (mode of `industry`):** `retail`  \n",
    "- **Q2 (largest abs corr among candidates):** (`annual_income`, `interaction_count`)  \n",
    "- **Q3 (highest mutual information):** `lead_source`  \n",
    "- **Q4 (validation accuracy, 2 decimals):** our exact result is ~**0.73**; the closest provided option is **0.74**  \n",
    "- **Q5 (smallest accuracy drop when removed):** `lead_score`  \n",
    "- **Q6 (best C, accuracy rounded to 3):** `0.01`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
